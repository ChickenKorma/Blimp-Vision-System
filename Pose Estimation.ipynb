{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Estimation Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "import keras.backend as K\n",
    "import math as m\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_prefix = \"D:/Uni Stuff/IP/Data/\"\n",
    "image_path_prefix = data_path_prefix + \"Blimp Images/Raw/image_\"\n",
    "\n",
    "blimp_vertices = np.array([[1, 1, 1], [1, 1, -1], [1, -1, 1], [1, -1, -1], [-1, 1, 1], [-1, 1, -1], [-1, -1, -1], [-1, -1, 1]])\n",
    "\n",
    "test_split = 0.25\n",
    "\n",
    "desired_image_size = 16\n",
    "\n",
    "image_columns = []\n",
    "colours = {0:\"R\", 1:\"G\", 2:\"B\"}\n",
    "\n",
    "# Create list of column names like '1 1 R', '1 1 G', '1 1 B', '1 2 R' etc\n",
    "for i in range(desired_image_size):\n",
    "    for j in range(desired_image_size):\n",
    "        for k in range(3):\n",
    "            image_columns.append(str(i + 1) + \" \" + str(j + 1) + \" \" + colours[k])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSVs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the bounding box and pose csv files and add to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_data = pd.read_csv(data_path_prefix + \"bbox data.csv\")\n",
    "\n",
    "pose_data = pd.read_csv(data_path_prefix + \"blimp poses.csv\")\n",
    "y_variables = list(pose_data.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the images from file, crop these by the bounding box and then resize to the desired square image size with padding to preserve aspect ratio. Image data is flattened and added to dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the image to the bounding box coordinates\n",
    "def cutout_image(image, bbox):\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "\n",
    "    center_x = bbox['cent_x'] * width\n",
    "    center_y = bbox['cent_y'] * height\n",
    "\n",
    "    bbox_width = bbox['width'] * width\n",
    "    bbox_height = bbox['height'] * height\n",
    "\n",
    "    min_x = np.clip(int(center_x - (bbox_width / 2)), 0, width)\n",
    "    max_x = np.clip(int(center_x + (bbox_width / 2)), 0, width) \n",
    "\n",
    "    min_y = np.clip(int(center_y - (bbox_height / 2)), 0, height)\n",
    "    max_y = np.clip(int(center_y + (bbox_height / 2)), 0, height)\n",
    "\n",
    "    return image[min_y:max_y, min_x:max_x]\n",
    "\n",
    "# Resize the image to the desired_image_size square and pad with black if necessary\n",
    "def resize_and_pad_image(image):\n",
    "    old_size = image.shape[:2]\n",
    "\n",
    "    size_ratio = float(desired_image_size) / max(old_size)\n",
    "\n",
    "    new_size = tuple([int(x * size_ratio) for x in old_size])\n",
    "\n",
    "    resized_image = cv.resize(image, (new_size[1], new_size[0]), interpolation=cv.INTER_AREA)\n",
    "\n",
    "    delta_w = desired_image_size - new_size[1]\n",
    "    delta_h = desired_image_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "    return cv.copyMakeBorder(resized_image, top, bottom, left, right, cv.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "images = pd.DataFrame(columns=image_columns)\n",
    "\n",
    "for i in range(len(pose_data)):\n",
    "    img = cv.imread(image_path_prefix + str(i) + \".png\")\n",
    "    cropped = cutout_image(img, bbox_data.iloc[i])\n",
    "    padded = resize_and_pad_image(cropped)\n",
    "\n",
    "    images.loc[len(images)] = padded.flatten()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the bounding box data and image data into one dataframe. Split that and pose data into the training and testing lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([bbox_data, images], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, pose_data, test_size=test_split)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unecessary variables from RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bbox_data\n",
    "del pose_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD Metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions to calculate ADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rotation matrix of an XYZ rotation with the euler angles vector\n",
    "def get_rotation_matrix(rot_vec):\n",
    "    x_matrix = np.matrix([[ 1, 0, 0],\n",
    "                          [ 0, m.cos(m.radians(rot_vec[0])),-m.sin(m.radians(rot_vec[0]))],                         \n",
    "                          [ 0, m.sin(m.radians(rot_vec[0])), m.cos(m.radians(rot_vec[0]))]])\n",
    "    \n",
    "    y_matrix = np.matrix([[ m.cos(m.radians(rot_vec[1])), 0, m.sin(m.radians(rot_vec[1]))],\n",
    "                          [ 0, 1, 0],\n",
    "                          [-m.sin(m.radians(rot_vec[1])), 0, m.cos(m.radians(rot_vec[1]))]])\n",
    "    \n",
    "    z_matrix = np.matrix([[ m.cos(m.radians(rot_vec[2])), -m.sin(m.radians(rot_vec[2])), 0 ],\n",
    "                          [ m.sin(m.radians(rot_vec[2])),  m.cos(m.radians(rot_vec[2])), 0 ],\n",
    "                          [ 0, 0, 1 ]])\n",
    "    \n",
    "    return z_matrix * y_matrix * x_matrix\n",
    "\n",
    "# Get the average distance between true and predicted model points\n",
    "def get_ADD(true_trans, true_rot_vec, pred_trans, pred_rot_vec):\n",
    "    true_rot = get_rotation_matrix(true_rot_vec).T\n",
    "    pred_rot = get_rotation_matrix(pred_rot_vec).T\n",
    "\n",
    "    total_distance = 0\n",
    "\n",
    "    for vertex_pos in blimp_vertices:\n",
    "        true_pos = np.matmul(true_rot, vertex_pos) - true_trans\n",
    "        pred_pos = np.matmul(pred_rot, vertex_pos) - pred_trans\n",
    "\n",
    "        distance = np.linalg.norm(true_pos - pred_pos)\n",
    "        total_distance += distance\n",
    "\n",
    "    return total_distance / len(blimp_vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADD_metric(y_true, y_pred):\n",
    "    true_trans = y_true[:3]\n",
    "    true_rot_vec = y_true[3:]\n",
    "\n",
    "    pred_trans = y_pred[:3]\n",
    "    pred_rot_vec = y_pred[3:]\n",
    "\n",
    "    #print(K.eval(true_trans))\n",
    "\n",
    "    try: \n",
    "        true_trans = K.eval(true_trans)\n",
    "        true_rot_vec = K.eval(true_rot_vec)\n",
    "        pred_trans = K.eval(pred_trans)\n",
    "        pred_rot_vec = K.eval(pred_rot_vec)\n",
    "    except:\n",
    "        return 10000\n",
    "\n",
    "    return get_ADD(true_trans, true_rot_vec, pred_trans, pred_rot_vec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create normalizer function based on input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the DNN model and print details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 08s]\n",
      "val_loss: 1.1847742795944214\n",
      "\n",
      "Best val_loss So Far: 1.1847742795944214\n",
      "Total elapsed time: 00h 00m 08s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "3                 |3                 |dense_layers\n",
      "32                |128               |nodes_per_layer\n",
      "\n",
      "Epoch 1/10\n",
      "  1/188 [..............................] - ETA: 1:33 - loss: 10.3137 - ADD_metric: 10000.0000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0059s). Check your callbacks.\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.5138 - ADD_metric: 10000.0000 - val_loss: 6.1882 - val_ADD_metric: 10000.0000\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.7358 - ADD_metric: 10000.0000 - val_loss: 5.1597 - val_ADD_metric: 10000.0000\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.4751 - ADD_metric: 10000.0000 - val_loss: 3.7877 - val_ADD_metric: 10000.0000\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.1291 - ADD_metric: 10000.0000 - val_loss: 2.7700 - val_ADD_metric: 10000.0000\n",
      "Epoch 5/10\n",
      "167/188 [=========================>....] - ETA: 0s - loss: 2.4781 - ADD_metric: 10000.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 31\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m#dnn_model = build_and_compile_model(normalizer, 2, 64, 'relu', tf.keras.optimizers.Adam(0.001))\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m#dnn_model.summary()\u001b[39;00m\n\u001b[0;32m     21\u001b[0m tuner \u001b[39m=\u001b[39m keras_tuner\u001b[39m.\u001b[39mRandomSearch(\n\u001b[0;32m     22\u001b[0m     build_and_compile_model,\n\u001b[0;32m     23\u001b[0m     max_trials\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     directory\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlogs/\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     29\u001b[0m )\n\u001b[1;32m---> 31\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(\n\u001b[0;32m     32\u001b[0m     X_train,\n\u001b[0;32m     33\u001b[0m     y_train,\n\u001b[0;32m     34\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[0;32m     35\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     36\u001b[0m     \u001b[39m# Use the TensorBoard callback.\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m     \u001b[39m# The logs will be write to \"/tmp/tb_logs\".\u001b[39;49;00m\n\u001b[0;32m     38\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mTensorBoard(\u001b[39m\"\u001b[39;49m\u001b[39mlogs/\u001b[39;49m\u001b[39m\"\u001b[39;49m)],\n\u001b[0;32m     39\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m    269\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    271\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[0;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 235\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[0;32m    237\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[0;32m    238\u001b[0m     ):\n\u001b[0;32m    239\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    240\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    241\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    243\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    244\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    251\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    286\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m--> 287\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_and_fit_model(trial, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    289\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[0;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner.py:214\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[0;32m    213\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 214\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mfit(hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    216\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m )\n\u001b[0;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    121\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \n\u001b[0;32m    123\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\frase\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\frase\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1729\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1715\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1716\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1717\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1727\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1728\u001b[0m     )\n\u001b[1;32m-> 1729\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1730\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1731\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1732\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1733\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1734\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1735\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1736\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1737\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1738\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1739\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1740\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1741\u001b[0m )\n\u001b[0;32m   1742\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1743\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1744\u001b[0m }\n\u001b[0;32m   1745\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\frase\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\frase\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:2072\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   2069\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   2070\u001b[0m ):\n\u001b[0;32m   2071\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2072\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   2073\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   2074\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\frase\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\frase\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\frase\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    931\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    932\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    934\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    935\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\frase\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\frase\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\frase\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\frase\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def build_and_compile_model(hp):\n",
    "  #NAME = f\"{dense_layers}x{nodes}-{activation}-{optimizer.name}({optimizer.learning_rate})-{int(time.time())}\"\n",
    "  #tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'logs/{NAME}')\n",
    "\n",
    "  layers = [normalizer]\n",
    "\n",
    "  for i in range(hp.Int(\"dense_layers\", 1, 5)):\n",
    "    layers.append(tf.keras.layers.Dense(hp.Int(\"nodes_per_layer\", 32, 128, step=32), activation='relu'))\n",
    "\n",
    "  layers.append(tf.keras.layers.Dense(6))\n",
    "\n",
    "  model = tf.keras.Sequential(layers)\n",
    "  model.compile(loss = 'mean_absolute_error', metrics=[ADD_metric], optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "\n",
    "  return model\n",
    "\n",
    "#dnn_model = build_and_compile_model(normalizer, 2, 64, 'relu', tf.keras.optimizers.Adam(0.001))\n",
    "#dnn_model.summary()\n",
    "\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_and_compile_model,\n",
    "    max_trials=10,\n",
    "    # Do not resume the previous search in the same directory.\n",
    "    overwrite=True,\n",
    "    objective=\"val_loss\",\n",
    "    # Set a directory to store the intermediate results.\n",
    "    directory=\"logs/\",\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    # Use the TensorBoard callback.\n",
    "    # The logs will be write to \"/tmp/tb_logs\".\n",
    "    callbacks=[tf.keras.callbacks.TensorBoard(\"logs/\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 7.1770 - val_loss: 5.7515\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 5.1764 - val_loss: 4.3988\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.7182 - val_loss: 3.2489\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 2.7465 - val_loss: 2.6129\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 2.2912 - val_loss: 2.1508\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.9085 - val_loss: 1.9212\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.6935 - val_loss: 1.7008\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.5440 - val_loss: 1.6850\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.4223 - val_loss: 1.4628\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.3297 - val_loss: 1.4826\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.2158 - val_loss: 1.3149\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.1927 - val_loss: 1.3886\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.1537 - val_loss: 1.2453\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0935 - val_loss: 1.1481\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0511 - val_loss: 1.1084\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0123 - val_loss: 1.1384\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.1383\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.9488 - val_loss: 1.0455\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.9600 - val_loss: 0.9904\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.9028 - val_loss: 0.9743\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.8986 - val_loss: 1.1757\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.8611 - val_loss: 1.0653\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.8542 - val_loss: 1.0782\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.8395 - val_loss: 0.9224\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.8144 - val_loss: 0.9498\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.8638 - val_loss: 0.8857\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.7873 - val_loss: 0.9374\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.7785 - val_loss: 0.8783\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.7646 - val_loss: 0.8613\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.7501 - val_loss: 0.8558\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.7608 - val_loss: 0.8857\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.7268 - val_loss: 0.9181\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.7218 - val_loss: 0.8205\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.7562 - val_loss: 0.8315\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.7232 - val_loss: 0.8184\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6740 - val_loss: 0.7937\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6885 - val_loss: 0.8387\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6766 - val_loss: 0.8537\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6677 - val_loss: 0.8186\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6805 - val_loss: 0.8035\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6479 - val_loss: 0.7797\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6851 - val_loss: 0.8185\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6504 - val_loss: 0.8456\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6546 - val_loss: 0.7509\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6428 - val_loss: 0.8030\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6347 - val_loss: 0.7852\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6216 - val_loss: 0.8256\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6217 - val_loss: 0.7706\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6144 - val_loss: 0.7413\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.6294 - val_loss: 0.7480\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6298 - val_loss: 0.8217\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.5956 - val_loss: 0.8066\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.6288 - val_loss: 0.8147\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.6153 - val_loss: 0.8025\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.6068 - val_loss: 0.7621\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.6032 - val_loss: 0.7601\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.5835 - val_loss: 0.7500\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.5811 - val_loss: 0.8020\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.5884 - val_loss: 0.7550\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.5869 - val_loss: 0.7053\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.5785 - val_loss: 0.7307\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.5684 - val_loss: 0.7529\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5675 - val_loss: 0.7480\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5758 - val_loss: 0.6765\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.5444 - val_loss: 0.7569\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.5920 - val_loss: 0.7478\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.5644 - val_loss: 0.7006\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5405 - val_loss: 0.7195\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5348 - val_loss: 0.7142\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5454 - val_loss: 0.7271\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5580 - val_loss: 0.7519\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5673 - val_loss: 0.6782\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5601 - val_loss: 0.7342\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5530 - val_loss: 0.7599\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5581 - val_loss: 0.7868\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 0.7562\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5315 - val_loss: 0.6803\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5304 - val_loss: 0.7286\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5202 - val_loss: 0.6663\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5142 - val_loss: 0.7336\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.7015\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5310 - val_loss: 0.6793\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5105 - val_loss: 0.7152\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5101 - val_loss: 0.6829\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5203 - val_loss: 0.7291\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 0.7567\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 0.6464\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 0.6417\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.4959 - val_loss: 0.6819\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 0.7137\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.4978 - val_loss: 0.6929\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 0.7958\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5214 - val_loss: 0.7745\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5080 - val_loss: 0.6857\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 0.6642\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.4965 - val_loss: 0.6724\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5212 - val_loss: 0.6450\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.6660\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.6397\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.7023\n"
     ]
    }
   ],
   "source": [
    "#dnn_history = dnn_model.fit(X_train, y_train, validation_split=0.2, epochs=100, callbacks=[callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and epoch graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "plot_loss(dnn_history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance out-of-sample on the testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 930us/step - loss: 1.1290 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1289503574371338, 1.0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the true and predicted poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:\n",
      "          pos_x      pos_y      pos_z     rot_x     rot_y     rot_z\n",
      "3741  20.333391   3.652711  -1.208845 -0.158652 -0.042135  0.263581\n",
      "9219  45.294640  15.791813   8.372956  0.171466 -0.366214 -0.734563\n",
      "355    9.493512  -5.401581   2.087808  0.142615 -0.042771  0.562513\n",
      "7448  31.546106  15.311429   0.649132 -0.138181  0.578481  0.622221\n",
      "3407  51.868752  -9.980073  -3.370181 -0.095203  0.483281  2.472045\n",
      "...         ...        ...        ...       ...       ...       ...\n",
      "7371   7.070657   4.513583  -2.096345  0.002727 -0.047692 -2.328843\n",
      "3808  34.753090  10.212715 -10.489415  0.046053  0.087386 -2.879217\n",
      "20    58.894653  30.144754 -18.557043  0.015419 -0.405312 -2.650370\n",
      "5851  60.550377 -21.700560 -14.656321  0.000121 -0.712185 -0.173900\n",
      "6012  26.096327 -15.570047  -0.801971 -0.034567 -0.118828  0.663250\n",
      "\n",
      "[2500 rows x 6 columns]\n",
      "Predicted:\n",
      "79/79 [==============================] - 0s 844us/step\n",
      "          pos_x      pos_y      pos_z     rot_x     rot_y     rot_z\n",
      "0     21.497316   5.192024  -0.746617  0.004034  0.212747  0.159360\n",
      "1     49.539635  21.822174   8.200601 -0.083620 -0.279057 -0.441821\n",
      "2      8.824695  -4.960892   2.370619 -0.125965  0.046894  1.062569\n",
      "3     35.776299  17.264191   0.925792 -0.033855  0.913378  0.895347\n",
      "4     61.045124  -8.446667  -8.711905 -0.082462  0.663765  3.264291\n",
      "...         ...        ...        ...       ...       ...       ...\n",
      "2495   7.961967   3.081017  -1.735411  0.048920  0.018295  0.526197\n",
      "2496  35.154171  10.741077  -7.825688 -0.054789  0.233749 -1.614440\n",
      "2497  63.900433  29.444111 -14.659226 -0.003579 -0.226732 -0.810415\n",
      "2498  61.242828 -18.883867 -11.702571  0.072364 -0.507564  0.102429\n",
      "2499  27.962275 -16.356867  -1.639849  0.060841 -0.142147  0.727549\n",
      "\n",
      "[2500 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual:\")\n",
    "print(y_test)\n",
    "\n",
    "print(\"Predicted:\")\n",
    "predictions = best_model.predict(X_test)\n",
    "print(pd.DataFrame(predictions, columns=y_variables))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
